{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lessons so far, we have mostly just used the default `.score()` method of fitted models.  For most or all classification models, this measures accuracy.  For most or all regression models, this measures $R^2$ (coefficient of determination).  As we have mentioned, the subpackage `sklearn.metrics` contains a large number of other scorers.  Depending on your purpose, one of these might be more appropriate.\n",
    "\n",
    "In this lesson we will look at a few such metrics, but we will also develop a custom metric that is not included in scikit-learn (and presumably never will be, for reasons we will see)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from src.setup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A slightly unbalanced classification\n",
    "\n",
    "For this lesson, we will look at the [Dermatology Data Set](https://archive.ics.uci.edu/ml/datasets/Dermatology) available from UCI.  This data contains 34 measurements of 36 patients, with each one diagnosed as having one of six skin conditions.  Our purpose in using this data is two-fold. On the one hand, we want to look at a multi-class classification problem, which we have not done extensively in these lessons.  But more interestingly at the end, we want to look at the value of non-top diagnoses, which may have utility for particular domain problems.\n",
    "\n",
    "> <small>Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digression on multi-labels\n",
    "\n",
    "Note that what we present here is **not** a multi-label problem.  In some situations it is useful to identify more than one class to which a sample might belong.  In the current domain, that would be patients who have multiple skin conditions at once.  Such is possible, but this dataset is assumed not to contain that situation.  Or in another domain, we might wish to characterize a photographic image by multiple classes.  For example, an image containing both a cat and a dog would get both of these labels, but would get none of the, e.g. other 98 available labels because those things were not in the image.  Multi-label problems can be addressed with scikit-learn.\n",
    "\n",
    "See the official documentation of [multiclass and multilabel algorithms](https://scikit-learn.org/stable/modules/multiclass.html).  Note that multi-output is related to multi-label, but is a somewhat different concept.  In multi-label, any number of labels may be identified (including zero).  This is akin to one-hot encoding, but of the output (maybe \"multi-hot\" would be a good description).  \n",
    "\n",
    "In contrast, mutli-output identified a fixed number of outputs, which we might think of as orthogonal dimensions of the output.  In a sense this is like the fixed number of input features.  For example, in the photo classification problem, we might always want to predict `(color, subject, lighting)` for every image.  So sometimes it is a \"brown dog in daylight\", other times it is a \"white cat at night.\"\n",
    "\n",
    "Basically all classification models can be transformed into multi-label algorithms by transforming the problem into a collection of one-vs-all classifiers.  For example, one model is cat-vs-not-cat; another model is dog-vs-not-dog.  Similarly for all of the stipulated 100 known classes.  If both the cat-vs-not-cat and dog-vs-not-dog models make a positive prediction, we would assign both those labels.  However, other models are inherently multi-label by their design, so this kind of transformation is irrelevant (and counter-productive, in fact) if you use those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "We get this data in somewhat raw form.  The `dermatology.data` file is a CSV with no headers.  The `dermatology.names` files contains a bit more than its name might suggest.  Beyond providing the feature names, it gives additional exposition of the dataset, such as value coding, where unknown values occur, and a few other things in prose.  I produced a code-friendly extraction of the relevant information below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histopathological Attributes: (values 0, 1, 2, 3)\n",
    "# Clinical Attributes: (values 0, 1, 2, 3, unless indicated)\n",
    "features = [\n",
    "    \"erythema\",\n",
    "    \"scaling\",\n",
    "    \"definite borders\",\n",
    "    \"itching\",\n",
    "    \"koebner phenomenon\",\n",
    "    \"polygonal papules\",\n",
    "    \"follicular papules\",\n",
    "    \"oral mucosal involvement\",\n",
    "    \"knee and elbow involvement\",\n",
    "    \"scalp involvement\",\n",
    "    \"family history\",  # 0 or 1\n",
    "    \"melanin incontinence\",\n",
    "    \"eosinophils in the infiltrate\",\n",
    "    \"PNL infiltrate\",\n",
    "    \"fibrosis of the papillary dermis\",\n",
    "    \"exocytosis\",\n",
    "    \"acanthosis\",\n",
    "    \"hyperkeratosis\",\n",
    "    \"parakeratosis\",\n",
    "    \"clubbing of the rete ridges\",\n",
    "    \"elongation of the rete ridges\",\n",
    "    \"thinning of the suprapapillary epidermis\",\n",
    "    \"spongiform pustule\",\n",
    "    \"munro microabcess\",\n",
    "    \"focal hypergranulosis\",\n",
    "    \"disappearance of the granular layer\",\n",
    "    \"vacuolisation and damage of basal layer\",\n",
    "    \"spongiosis\",\n",
    "    \"saw-tooth appearance of retes\",\n",
    "    \"follicular horn plug\",\n",
    "    \"perifollicular parakeratosis\",\n",
    "    \"inflammatory monoluclear inflitrate\",\n",
    "    \"band-like infiltrate\",\n",
    "    \"Age\",  # linear; missing marked '?'\n",
    "    \"TARGET\"  # See mapping\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference and later use, the dictionary `targets` contains the class code and name of the skin condition diagnosed.  We also not here the number of obvservations of each condition.  They are somewhat imbalanced, which might affect the metrics we use.  That is, in this dataset, psorisis is much more common than pilaris.  I am not a dermatologist, and have no idea what the prevalence of these conditions is in the general population; there may have been selection bias in this aggregation.  That is, beyond the obvious selection bias that people with no skin conditions at all are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {\n",
    "    1:\"psoriasis\",                 # 112 instances\n",
    "    2:\"seboreic dermatitis\",       # 61\n",
    "    3:\"lichen planus\",             # 72\n",
    "    4:\"pityriasis rosea\",          # 49\n",
    "    5:\"cronic dermatitis\",         # 52    \n",
    "    6:\"pityriasis rubra pilaris\",  # 20\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data needs minor massaging to be ready for use.  To have a friendly DataFrame to work with, we attach the names of the features as columns.  But the missing `Age` that is marked with a questino mark needs extra clean-up.  I have decided to impute the median age for missing data. Other approaches are possible, and some models will work with missing data.  As my domain judgement, I chose this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>erythema</th>\n",
       "      <th>scaling</th>\n",
       "      <th>definite borders</th>\n",
       "      <th>itching</th>\n",
       "      <th>koebner phenomenon</th>\n",
       "      <th>polygonal papules</th>\n",
       "      <th>follicular papules</th>\n",
       "      <th>oral mucosal involvement</th>\n",
       "      <th>knee and elbow involvement</th>\n",
       "      <th>scalp involvement</th>\n",
       "      <th>...</th>\n",
       "      <th>disappearance of the granular layer</th>\n",
       "      <th>vacuolisation and damage of basal layer</th>\n",
       "      <th>spongiosis</th>\n",
       "      <th>saw-tooth appearance of retes</th>\n",
       "      <th>follicular horn plug</th>\n",
       "      <th>perifollicular parakeratosis</th>\n",
       "      <th>inflammatory monoluclear inflitrate</th>\n",
       "      <th>band-like infiltrate</th>\n",
       "      <th>Age</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     erythema  scaling  definite borders  itching  koebner phenomenon  \\\n",
       "0           2        2                 0        3                   0   \n",
       "1           3        3                 3        2                   1   \n",
       "2           2        1                 2        3                   1   \n",
       "3           2        2                 2        0                   0   \n",
       "4           2        3                 2        2                   2   \n",
       "..        ...      ...               ...      ...                 ...   \n",
       "361         2        1                 1        0                   1   \n",
       "362         3        2                 1        0                   1   \n",
       "363         3        2                 2        2                   3   \n",
       "364         2        1                 3        1                   2   \n",
       "365         3        2                 2        0                   0   \n",
       "\n",
       "     polygonal papules  follicular papules  oral mucosal involvement  \\\n",
       "0                    0                   0                         0   \n",
       "1                    0                   0                         0   \n",
       "2                    3                   0                         3   \n",
       "3                    0                   0                         0   \n",
       "4                    2                   0                         2   \n",
       "..                 ...                 ...                       ...   \n",
       "361                  0                   0                         0   \n",
       "362                  0                   0                         0   \n",
       "363                  2                   0                         2   \n",
       "364                  3                   0                         2   \n",
       "365                  0                   0                         0   \n",
       "\n",
       "     knee and elbow involvement  scalp involvement  ...  \\\n",
       "0                             1                  0  ...   \n",
       "1                             1                  1  ...   \n",
       "2                             0                  0  ...   \n",
       "3                             3                  2  ...   \n",
       "4                             0                  0  ...   \n",
       "..                          ...                ...  ...   \n",
       "361                           0                  0  ...   \n",
       "362                           0                  0  ...   \n",
       "363                           0                  0  ...   \n",
       "364                           0                  0  ...   \n",
       "365                           3                  3  ...   \n",
       "\n",
       "     disappearance of the granular layer  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      3   \n",
       "4                                      2   \n",
       "..                                   ...   \n",
       "361                                    0   \n",
       "362                                    1   \n",
       "363                                    0   \n",
       "364                                    0   \n",
       "365                                    2   \n",
       "\n",
       "     vacuolisation and damage of basal layer  spongiosis  \\\n",
       "0                                          0           3   \n",
       "1                                          0           0   \n",
       "2                                          2           3   \n",
       "3                                          0           0   \n",
       "4                                          3           2   \n",
       "..                                       ...         ...   \n",
       "361                                        0           1   \n",
       "362                                        0           1   \n",
       "363                                        3           0   \n",
       "364                                        2           0   \n",
       "365                                        0           0   \n",
       "\n",
       "     saw-tooth appearance of retes  follicular horn plug  \\\n",
       "0                                0                     0   \n",
       "1                                0                     0   \n",
       "2                                2                     0   \n",
       "3                                0                     0   \n",
       "4                                3                     0   \n",
       "..                             ...                   ...   \n",
       "361                              0                     0   \n",
       "362                              0                     0   \n",
       "363                              3                     0   \n",
       "364                              1                     0   \n",
       "365                              0                     0   \n",
       "\n",
       "     perifollicular parakeratosis  inflammatory monoluclear inflitrate  \\\n",
       "0                               0                                    1   \n",
       "1                               0                                    1   \n",
       "2                               0                                    2   \n",
       "3                               0                                    3   \n",
       "4                               0                                    2   \n",
       "..                            ...                                  ...   \n",
       "361                             0                                    2   \n",
       "362                             0                                    2   \n",
       "363                             0                                    2   \n",
       "364                             0                                    2   \n",
       "365                             0                                    3   \n",
       "\n",
       "     band-like infiltrate   Age  TARGET  \n",
       "0                       0  55.0       2  \n",
       "1                       0   8.0       1  \n",
       "2                       3  26.0       3  \n",
       "3                       0  40.0       1  \n",
       "4                       3  45.0       3  \n",
       "..                    ...   ...     ...  \n",
       "361                     0  25.0       4  \n",
       "362                     0  36.0       4  \n",
       "363                     3  28.0       3  \n",
       "364                     3  50.0       3  \n",
       "365                     0  35.0       1  \n",
       "\n",
       "[366 rows x 35 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/dermatology.data', header=None, names=features)\n",
    "df.loc[df.Age == '?', 'Age'] = None\n",
    "df['Age'] = df.Age.astype(float)\n",
    "df.loc[df.Age.isnull(), 'Age'] = df.Age.median()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "The usual steps can be done here.  We create our X and y arrays for the features and target.  We perform a train/test split on the data.  For this problem, we will use a k-nearest neighbors model.  I have not tried a wide variety of models or hyperparameters, and have no idea what the \"best\" model is.  But KNN is often quite good, and it is a good way to illustrate the concepts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also create a collection of predictions against the test data that we will utilize below.  For convenience, we can transform the array result into a Pandas Series so that the index matches between the ground truth of the training data and the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247              psoriasis\n",
       "127          lichen planus\n",
       "230    seboreic dermatitis\n",
       "162          lichen planus\n",
       "159    seboreic dermatitis\n",
       "              ...         \n",
       "321    seboreic dermatitis\n",
       "59     seboreic dermatitis\n",
       "12     seboreic dermatitis\n",
       "312          lichen planus\n",
       "107              psoriasis\n",
       "Length: 92, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pd.Series(knn.predict(X_test), index=y_test.index)\n",
    "y_pred.map(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the trained model\n",
    "\n",
    "So far, so good.  The usual fit-then-score steps work as expected.  But in particular, we simply used the default `.score()` method attached to the trained model object.  For this classification, that default is *accuracy*.  We saw earlier, in the introductory material, that depending on our purpose, accuracy might not be the most useful metric.  \n",
    "\n",
    "The decision of a metric is very much driven by our \"business requirement\" and there is not single objective answer.  However, one thing that is absolute is that when we get to comparing different models to each other—whether entirely different styles of models, or different hyperparameters—we need some way of quantifying the **goodness** of a model to choose which one to keep.  In particular, in practical terms we need to reduce tha \"goodness\" to a single number we can compare among modeling approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, recall, and f1 score\n",
    "\n",
    "How good is our fitted model by some other metrics we dicussed in the very first [\"What Is Machine Learning?\"](WhatIsML.ipynb) lesson.  Perhaps you should review that lesson for the following discussion.  One matter is that the default \"averaging\" technique assumes a binary classification.  For our multi-class model we have to chose something different.  There are three options here:\n",
    "\n",
    "* 'micro': Count false positives, false negatives, true positives, true negatives for all observations independently, and simply perform row-wise aggregation of the counts.\n",
    "* 'macro': Count the true and false categories grouping by class label, and take the mean of all those scores per label.\n",
    "* 'weighted': Similar to macro, but take a weighted average based on the \"support\" (frequency) of each different label.\n",
    "\n",
    "Again, there is no uniformly right answer to which of these is the best.  It depends on your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9139386189258313"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867564534231201"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred, y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are not especially far apart, but the different metrics absolutely give us different results.  Which one we choose will give different answers for which model we should choose for the production system.  \n",
    "\n",
    "Let us create a different model and compare it to the first one under different metrics.  A confession here is that I easily identified a number of models types and hyperparameters that are clearly better than the first one under almost any metric.  The `knn` and `knn2` objects are simply \"naive\" attempts that show the pattern I want to demonstrate.  That is, among these two models, chosing one is sensitive to which metric you prefer.  But for those better models I found, the same general pattern will emerge, just with higher numbers on each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=2, metric=\"manhattan\")\n",
    "knn2.fit(X_train, y_train)\n",
    "y_pred2 = knn2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: 0.9130434782608695\n",
      "Model 2: 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "print('Model 1:', precision_score(y_pred, y_test, average='micro'))\n",
    "print('Model 2:', precision_score(y_pred2, y_test, average='micro'))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: 0.9139386189258313\n",
      "Model 2: 0.876764539808018\n"
     ]
    }
   ],
   "source": [
    "print('Model 1:', f1_score(y_pred, y_test, average='weighted'))\n",
    "print('Model 2:', f1_score(y_pred2, y_test, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: 0.867564534231201\n",
      "Model 2: 0.9017094017094017\n"
     ]
    }
   ],
   "source": [
    "print('Model 1:', recall_score(y_pred, y_test, average='macro'))\n",
    "print('Model 2:', recall_score(y_pred2, y_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisiting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = y_test.value_counts().sort_index()\n",
    "weights = 1/counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9130434782608695\n",
      "0.867564534231201\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, y_test))\n",
    "print(balanced_accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8991012410142091"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = y.value_counts().sort_index()\n",
    "weights = 1/counts\n",
    "balanced_accuracy_score(y_pred, y_test, sample_weight=y_test.map(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247    1\n",
       "127    1\n",
       "230    1\n",
       "162    1\n",
       "159    1\n",
       "      ..\n",
       "321    1\n",
       "59     1\n",
       "12     1\n",
       "312    1\n",
       "107    1\n",
       "Length: 92, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_plurality = 1 + (y_pred*0)\n",
    "y_plurality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29347826086956524"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_plurality, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29347826086956524"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_plurality, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44068784610900613"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_plurality, y_test, sample_weight=y_test.map(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17078893196892914"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_plurality, y_test, sample_weight=y_test.map(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psoriasis</th>\n",
       "      <th>seboreic dermatitis</th>\n",
       "      <th>lichen planus</th>\n",
       "      <th>pityriasis rosea</th>\n",
       "      <th>cronic dermatitis</th>\n",
       "      <th>pityriasis rubra pilaris</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    psoriasis  seboreic dermatitis  lichen planus  pityriasis rosea  \\\n",
       "0         1.0                  0.0            0.0               0.0   \n",
       "1         0.0                  0.0            1.0               0.0   \n",
       "2         0.0                  0.6            0.0               0.4   \n",
       "3         0.0                  0.0            0.8               0.2   \n",
       "4         0.0                  0.6            0.0               0.4   \n",
       "..        ...                  ...            ...               ...   \n",
       "87        0.0                  0.6            0.0               0.4   \n",
       "88        0.0                  1.0            0.0               0.0   \n",
       "89        0.0                  1.0            0.0               0.0   \n",
       "90        0.0                  0.0            1.0               0.0   \n",
       "91        1.0                  0.0            0.0               0.0   \n",
       "\n",
       "    cronic dermatitis  pityriasis rubra pilaris  \n",
       "0                 0.0                       0.0  \n",
       "1                 0.0                       0.0  \n",
       "2                 0.0                       0.0  \n",
       "3                 0.0                       0.0  \n",
       "4                 0.0                       0.0  \n",
       "..                ...                       ...  \n",
       "87                0.0                       0.0  \n",
       "88                0.0                       0.0  \n",
       "89                0.0                       0.0  \n",
       "90                0.0                       0.0  \n",
       "91                0.0                       0.0  \n",
       "\n",
       "[92 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = pd.DataFrame(knn.predict_proba(X_test), columns=targets.values())\n",
    "probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
